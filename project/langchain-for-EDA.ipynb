{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dae293-9a5e-4460-8051-1a95ce0832e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67aea671-ef3d-4bf9-bca9-f8214e21a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain.llms import OpenAI\n",
    "from pyspark.sql import SparkSession\n",
    "from langchain.agents import create_spark_dataframe_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bf78e9-10a3-4f34-895d-d6e741c549c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your key: ········\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "os.environ['OPENAI_API_KEY'] = openai.api_key = getpass(\"Insert your key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0431e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>4</td>\n",
       "      <td>Single</td>\n",
       "      <td>5993</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>Married</td>\n",
       "      <td>5130</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Laboratory Technician</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>2090</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "\n",
       "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                        2  Female          94               3         2   \n",
       "1                        3    Male          61               2         2   \n",
       "2                        4    Male          92               2         1   \n",
       "\n",
       "                 JobRole  JobSatisfaction MaritalStatus  MonthlyIncome  \\\n",
       "0        Sales Executive                4        Single           5993   \n",
       "1     Research Scientist                2       Married           5130   \n",
       "2  Laboratory Technician                3        Single           2090   \n",
       "\n",
       "   MonthlyRate  NumCompaniesWorked Over18 OverTime  PercentSalaryHike  \\\n",
       "0        19479                   8      Y      Yes                 11   \n",
       "1        24907                   1      Y       No                 23   \n",
       "2         2396                   6      Y      Yes                 15   \n",
       "\n",
       "   PerformanceRating  RelationshipSatisfaction  StandardHours  \\\n",
       "0                  3                         1             80   \n",
       "1                  4                         4             80   \n",
       "2                  3                         2             80   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                 0                  8                      0   \n",
       "1                 1                 10                      3   \n",
       "2                 0                  7                      3   \n",
       "\n",
       "   WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                1               6                   4   \n",
       "1                3              10                   7   \n",
       "2                3               0                   0   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                     5  \n",
       "1                        1                     7  \n",
       "2                        0                     0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "csv_file_path = \"data/hr_ibm.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2cf29c34-a7ac-48e6-ada0-dfdbfb46c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out how many rows are in the dataframe\n",
      "Action: python_repl_ast\n",
      "Action Input: df.count()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1470\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 1470 rows in the dataframe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 1470 rows in the dataframe.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"text-davinci-003\"\n",
    "\n",
    "model = OpenAI(temperature=0, model=MODEL_ID)\n",
    "\n",
    "agent = create_spark_dataframe_agent(\n",
    "    llm=model,\n",
    "    df=df,\n",
    "    verbose=True\n",
    ")\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f923db1-a44e-408a-af52-84055f451d40",
   "metadata": {},
   "source": [
    "## Multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "193799b7-4a44-4fbd-b3af-f156c2c7562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain.llms.base import BaseLLM\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.agents.agent_toolkits.spark.base import _validate_spark_connect_df, _validate_spark_df\n",
    "from langchain.tools.python.tool import PythonAstREPLTool\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "\n",
    "PREFIX = \"\"\"\n",
    "You are working with a list of spark dataframes in Python. The name of the dataframes are `{dataframe_names}`.\n",
    "You should use the tools below to answer the question posed of you:\"\"\"\n",
    "\n",
    "SUFFIX = \"\"\"\n",
    "This is the result of `print(df.first())`:\n",
    "{dataframe_names}\n",
    "\n",
    "Begin!\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "def create_multiple_spark_dataframes_agent(\n",
    "    llm: BaseLLM,\n",
    "    dataframes_dict: Dict[str, pyspark.sql.DataFrame],\n",
    "    callback_manager: Optional[BaseCallbackManager] = None,\n",
    "    prefix: str = PREFIX,\n",
    "    suffix: str = SUFFIX,\n",
    "    input_variables: Optional[List[str]] = None,\n",
    "    verbose: bool = False,\n",
    "    return_intermediate_steps: bool = False,\n",
    "    max_iterations: Optional[int] = 15,\n",
    "    max_execution_time: Optional[float] = None,\n",
    "    early_stopping_method: str = \"force\",\n",
    "    agent_executor_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> AgentExecutor:\n",
    "    \"\"\"Construct a spark agent from an LLM and dataframe.\"\"\"\n",
    "\n",
    "    valid_dataframes = all([_validate_spark_df(df) for df in dataframes_dict.values()])\n",
    "    valid_spark_connect = all([_validate_spark_connect_df(df) for df in dataframes_dict.values()])\n",
    "\n",
    "    if not valid_dataframes and not valid_spark_connect:\n",
    "        raise ValueError(\"Spark is not installed. run `pip install pyspark`.\")\n",
    "\n",
    "    prefix = PREFIX.format(dataframe_names=\"`, `\".join([f\"{key}\" for key in dataframes_dict.keys()]))\n",
    "    \n",
    "    suffix = SUFFIX.format(\n",
    "        dataframe_names=\", \".join([f\"{{{key}}}\" for key in dataframes_dict.keys()]),\n",
    "        input=\"{input}\",\n",
    "        agent_scratchpad=\"{agent_scratchpad}\",\n",
    "    )\n",
    "\n",
    "    if input_variables is None:\n",
    "        input_variables = list(dataframes_dict.keys()) + [\"input\", \"agent_scratchpad\"]\n",
    "    \n",
    "        \n",
    "    tools = [PythonAstREPLTool(locals=dataframes_dict)]\n",
    "\n",
    "    prompt = ZeroShotAgent.create_prompt(\n",
    "        tools, prefix=prefix, suffix=suffix, input_variables=input_variables\n",
    "    )\n",
    "\n",
    "    promp_opts = {key: str(value.first()) for key, value in dataframes_dict.items()}\n",
    "    partial_prompt = prompt.partial(**promp_opts)\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=partial_prompt,\n",
    "        callback_manager=callback_manager,\n",
    "    )\n",
    "    tool_names = [tool.name for tool in tools]\n",
    "    agent = ZeroShotAgent(\n",
    "        llm_chain=llm_chain,\n",
    "        allowed_tools=tool_names,\n",
    "        callback_manager=callback_manager,\n",
    "        **kwargs,\n",
    "    )\n",
    "    return AgentExecutor.from_agent_and_tools(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        callback_manager=callback_manager,\n",
    "        verbose=verbose,\n",
    "        return_intermediate_steps=return_intermediate_steps,\n",
    "        max_iterations=max_iterations,\n",
    "        max_execution_time=max_execution_time,\n",
    "        early_stopping_method=early_stopping_method,\n",
    "        **(agent_executor_kwargs or {}),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6c74a3f-1e6c-4f02-9357-3167912b99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empresa_1 = spark.createDataFrame([(1, 'a'), (2,'b')], ['cnpj', 'classe'])\n",
    "df_empresa_2 = spark.createDataFrame([(1, 'x'), (2,'y'), (3, 'z')], ['cnpj', 'value'])\n",
    "\n",
    "my_dfs_dict = {'df_empresa_1': df_empresa_1, 'df_empresa_2': df_empresa_2}\n",
    "\n",
    "model = OpenAI(temperature=0, model=\"text-davinci-003\")\n",
    "\n",
    "agent = create_multiple_spark_dataframes_agent(\n",
    "    llm=model,\n",
    "    dataframes_dict=my_dfs_dict,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "349cf6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out how many rows are in the dataframe\n",
      "Action: python_repl_ast\n",
      "Action Input: df_empresa_1.count()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 2 rows in df_empresa_1.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 2 rows in df_empresa_1.'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many rows are in df_empresa_1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "86ab8752-7aad-4e78-b456-c4a13cd37d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out how many rows are in the dataframe\n",
      "Action: python_repl_ast\n",
      "Action Input: len(df_empresa_2.collect())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m3\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 3 rows in df_empresa_2.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 3 rows in df_empresa_2.'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how many rows are in df_empresa_2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c3672d4-85fe-47b6-9b1b-276470b0e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: preciso juntar os dois dataframes\n",
      "Action: python_repl_ast\n",
      "Action Input: df_empresa_1.join(df_empresa_2, on='cnpj')\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDataFrame[cnpj: bigint, classe: string, value: string]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Agora eu tenho o dataframe final\n",
      "Final Answer: O dataframe final é DataFrame[cnpj: bigint, classe: string, value: string]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O dataframe final é DataFrame[cnpj: bigint, classe: string, value: string]'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"faça o join das duas tabelas e retorne o dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea47c9b-9d4d-4609-8a31-8357db4792b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099da648-acab-4a68-b253-10dbe43e2845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1a77a-fcef-4ece-9494-82cb0dcfd875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d1c214c-b756-4300-923d-99fc65909ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A distributed collection of data grouped into named columns.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
      "    and can be created using various functions in :class:`SparkSession`:\n",
      "\n",
      "    >>> people = spark.createDataFrame([\n",
      "    ...     {\"deptId\": 1, \"age\": 40, \"name\": \"Hyukjin Kwon\", \"gender\": \"M\", \"salary\": 50},\n",
      "    ...     {\"deptId\": 1, \"age\": 50, \"name\": \"Takuya Ueshin\", \"gender\": \"M\", \"salary\": 100},\n",
      "    ...     {\"deptId\": 2, \"age\": 60, \"name\": \"Xinrong Meng\", \"gender\": \"F\", \"salary\": 150},\n",
      "    ...     {\"deptId\": 3, \"age\": 20, \"name\": \"Haejoon Lee\", \"gender\": \"M\", \"salary\": 200}\n",
      "    ... ])\n",
      "\n",
      "    Once created, it can be manipulated using the various domain-specific-language\n",
      "    (DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
      "\n",
      "    To select a column from the :class:`DataFrame`, use the apply method:\n",
      "\n",
      "    >>> age_col = people.age\n",
      "\n",
      "    A more concrete example:\n",
      "\n",
      "    >>> # To create DataFrame using SparkSession\n",
      "    ... department = spark.createDataFrame([\n",
      "    ...     {\"id\": 1, \"name\": \"PySpark\"},\n",
      "    ...     {\"id\": 2, \"name\": \"ML\"},\n",
      "    ...     {\"id\": 3, \"name\": \"Spark SQL\"}\n",
      "    ... ])\n",
      "\n",
      "    >>> people.filter(people.age > 30).join(\n",
      "    ...     department, people.deptId == department.id).groupBy(\n",
      "    ...     department.name, \"gender\").agg({\"salary\": \"avg\", \"age\": \"max\"}).show()\n",
      "    +-------+------+-----------+--------+\n",
      "    |   name|gender|avg(salary)|max(age)|\n",
      "    +-------+------+-----------+--------+\n",
      "    |     ML|     F|      150.0|      60|\n",
      "    |PySpark|     M|       75.0|      50|\n",
      "    +-------+------+-----------+--------+\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    A DataFrame should only be created as described above. It should not be directly\n",
      "    created via using the constructor.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(df_empresa_1.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10eb2f94-589f-4108-b60d-8987d8ff86fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_collect_as_arrow',\n",
       " '_jcols',\n",
       " '_jdf',\n",
       " '_jmap',\n",
       " '_joinAsOf',\n",
       " '_jseq',\n",
       " '_lazy_rdd',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_schema',\n",
       " '_session',\n",
       " '_sort_cols',\n",
       " '_sql_ctx',\n",
       " '_support_repr_html',\n",
       " '_to_corrected_pandas_type',\n",
       " 'agg',\n",
       " 'alias',\n",
       " 'approxQuantile',\n",
       " 'cache',\n",
       " 'checkpoint',\n",
       " 'coalesce',\n",
       " 'colRegex',\n",
       " 'collect',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'createGlobalTempView',\n",
       " 'createOrReplaceGlobalTempView',\n",
       " 'createOrReplaceTempView',\n",
       " 'createTempView',\n",
       " 'crossJoin',\n",
       " 'crosstab',\n",
       " 'cube',\n",
       " 'describe',\n",
       " 'distinct',\n",
       " 'drop',\n",
       " 'dropDuplicates',\n",
       " 'drop_duplicates',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'exceptAll',\n",
       " 'explain',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'foreach',\n",
       " 'foreachPartition',\n",
       " 'freqItems',\n",
       " 'groupBy',\n",
       " 'groupby',\n",
       " 'head',\n",
       " 'hint',\n",
       " 'inputFiles',\n",
       " 'intersect',\n",
       " 'intersectAll',\n",
       " 'isEmpty',\n",
       " 'isLocal',\n",
       " 'isStreaming',\n",
       " 'is_cached',\n",
       " 'join',\n",
       " 'limit',\n",
       " 'localCheckpoint',\n",
       " 'mapInArrow',\n",
       " 'mapInPandas',\n",
       " 'melt',\n",
       " 'na',\n",
       " 'observe',\n",
       " 'orderBy',\n",
       " 'pandas_api',\n",
       " 'persist',\n",
       " 'printSchema',\n",
       " 'randomSplit',\n",
       " 'rdd',\n",
       " 'registerTempTable',\n",
       " 'repartition',\n",
       " 'repartitionByRange',\n",
       " 'replace',\n",
       " 'rollup',\n",
       " 'sameSemantics',\n",
       " 'sample',\n",
       " 'sampleBy',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'selectExpr',\n",
       " 'semanticHash',\n",
       " 'show',\n",
       " 'sort',\n",
       " 'sortWithinPartitions',\n",
       " 'sparkSession',\n",
       " 'sql_ctx',\n",
       " 'stat',\n",
       " 'storageLevel',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to',\n",
       " 'toDF',\n",
       " 'toJSON',\n",
       " 'toLocalIterator',\n",
       " 'toPandas',\n",
       " 'to_koalas',\n",
       " 'to_pandas_on_spark',\n",
       " 'transform',\n",
       " 'union',\n",
       " 'unionAll',\n",
       " 'unionByName',\n",
       " 'unpersist',\n",
       " 'unpivot',\n",
       " 'where',\n",
       " 'withColumn',\n",
       " 'withColumnRenamed',\n",
       " 'withColumns',\n",
       " 'withColumnsRenamed',\n",
       " 'withMetadata',\n",
       " 'withWatermark',\n",
       " 'write',\n",
       " 'writeStream',\n",
       " 'writeTo']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df_empresa_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
